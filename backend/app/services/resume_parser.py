"""
Resume Parser Service using Gemini for intelligent OCR and data extraction.
Converts PDF resumes to images and extracts structured data with LLM.
"""
import io
import json
import base64
from typing import List, Optional
from pydantic import BaseModel, Field
import fitz  # PyMuPDF

from ..config import get_settings

settings = get_settings()

# ============================================================================
# Multi-API Key Rotation for Gemini (handles quota limits)
# ============================================================================

class GeminiClientPool:
    """
    Pool of Gemini clients with automatic rotation on quota errors.
    Ensures resume parsing succeeds even if one API key hits its limit.
    """
    def __init__(self):
        self._clients = []
        self._current_index = 0
        self._initialized = False
        self._failed_keys = set()  # Track keys that hit quota

    def _initialize(self):
        """Initialize all Gemini clients from available API keys."""
        if self._initialized:
            return

        api_keys = settings.get_gemini_api_keys()
        if not api_keys:
            print("WARNING: No GEMINI_API_KEY(s) set - resume parsing disabled")
            self._initialized = True
            return

        try:
            from google import genai
            for i, key in enumerate(api_keys):
                try:
                    client = genai.Client(api_key=key)
                    self._clients.append({"client": client, "key_index": i})
                    print(f"âœ… Gemini client {i+1}/{len(api_keys)} initialized")
                except Exception as e:
                    print(f"WARNING: Failed to init Gemini client {i+1}: {e}")
        except ImportError:
            print("WARNING: google-genai package not installed")

        self._initialized = True
        print(f"Gemini client pool: {len(self._clients)} clients available")

    def get_client(self):
        """Get the current Gemini client."""
        self._initialize()
        if not self._clients:
            return None
        return self._clients[self._current_index]["client"]

    def rotate_on_quota_error(self) -> bool:
        """
        Rotate to next client when current hits quota.
        Returns True if rotation successful, False if all keys exhausted.
        """
        if len(self._clients) <= 1:
            return False

        self._failed_keys.add(self._current_index)

        # Find next working key
        for _ in range(len(self._clients)):
            self._current_index = (self._current_index + 1) % len(self._clients)
            if self._current_index not in self._failed_keys:
                print(f"ğŸ”„ Rotated to Gemini API key {self._current_index + 1}")
                return True

        print("âš ï¸ All Gemini API keys exhausted")
        return False

    def reset_failed_keys(self):
        """Reset failed keys (call periodically or on new day)."""
        self._failed_keys.clear()

    @property
    def available_clients_count(self) -> int:
        """Number of clients that haven't failed."""
        self._initialize()
        return len(self._clients) - len(self._failed_keys)


# Global client pool
_gemini_pool = GeminiClientPool()

def get_genai_client():
    """Get the current Gemini client from the pool."""
    return _gemini_pool.get_client()

def rotate_gemini_client() -> bool:
    """Rotate to next Gemini client on quota error."""
    return _gemini_pool.rotate_on_quota_error()


# ============================================================================
# Pydantic Schemas for Validated Output
# ============================================================================

class PersonalInfo(BaseModel):
    name: Optional[str] = None
    email: Optional[str] = None
    phone: Optional[str] = None
    linkedin_url: Optional[str] = None
    github_url: Optional[str] = None
    portfolio_url: Optional[str] = None
    location: Optional[str] = None


class EducationEntry(BaseModel):
    school: str
    degree: Optional[str] = None
    field_of_study: Optional[str] = None
    start_year: Optional[int] = None
    end_year: Optional[int] = None
    gpa: Optional[str] = None


class WorkExperienceEntry(BaseModel):
    company: str
    role: str
    city: Optional[str] = None
    country: Optional[str] = None
    start_date: Optional[str] = None  # YYYY-MM format
    end_date: Optional[str] = None
    is_current: bool = False
    description: Optional[str] = None


class ProjectEntry(BaseModel):
    name: str
    description: Optional[str] = None
    technologies: List[str] = Field(default_factory=list)
    start_year: Optional[int] = None
    end_year: Optional[int] = None
    url: Optional[str] = None


class SkillEntry(BaseModel):
    name: str
    category: Optional[str] = None  # language, framework, database, cloud, tool, soft_skill
    proficiency: Optional[str] = None  # expert, intermediate, beginner


class CertificationEntry(BaseModel):
    title: str
    issuer: Optional[str] = None
    year: Optional[int] = None
    url: Optional[str] = None


class PublicationEntry(BaseModel):
    title: str
    publisher: Optional[str] = None
    year: Optional[int] = None
    url: Optional[str] = None


class AwardEntry(BaseModel):
    title: str
    issuer: Optional[str] = None
    year: Optional[int] = None


class LanguageEntry(BaseModel):
    language: str
    proficiency: Optional[str] = None  # native, fluent, intermediate, basic


class CodingProfiles(BaseModel):
    leetcode: Optional[str] = None
    github: Optional[str] = None
    codechef: Optional[str] = None
    codeforces: Optional[str] = None


class ParsedResume(BaseModel):
    """Complete parsed resume schema"""
    personal_info: PersonalInfo = Field(default_factory=PersonalInfo)
    professional_summary: Optional[str] = None
    years_of_experience: Optional[float] = None
    current_role: Optional[str] = None
    current_company: Optional[str] = None
    education: List[EducationEntry] = Field(default_factory=list)
    work_experience: List[WorkExperienceEntry] = Field(default_factory=list)
    projects: List[ProjectEntry] = Field(default_factory=list)
    skills: List[SkillEntry] = Field(default_factory=list)
    certifications: List[CertificationEntry] = Field(default_factory=list)
    publications: List[PublicationEntry] = Field(default_factory=list)
    awards: List[AwardEntry] = Field(default_factory=list)
    languages: List[LanguageEntry] = Field(default_factory=list)
    coding_profiles: CodingProfiles = Field(default_factory=CodingProfiles)


# ============================================================================
# Resume Parsing Prompt
# ============================================================================

RESUME_PARSER_PROMPT = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                           ENTERPRISE RESUME PARSER v3.0 - PRODUCTION GRADE                          â•‘
â•‘                    Competitive with: Sovren, Textkernel, HireAbility, DaXtra, Affinda               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

You are an enterprise-grade Intelligent Document Processing (IDP) system specialized in resume/CV parsing.
Your parsing accuracy must meet or exceed industry standards (95%+ field-level accuracy).

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODULE 1: DOCUMENT INTELLIGENCE & PRE-PROCESSING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1.1 OCR ERROR CORRECTION MATRIX                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CHARACTER SUBSTITUTION PATTERNS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pattern    â”‚ Corrections                                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Letters    â”‚ 0â†”O, 1â†”lâ†”Iâ†”|, rnâ†”m, clâ†”d, vvâ†”w, iiâ†”u, fiâ†”fi, flâ†”fl, ffâ†”ff, Sâ†”5, Bâ†”8, Zâ†”2, gâ†”q       â”‚
â”‚ Symbols    â”‚ @â†”Â©â†”Â®, &â†”8, #â†”H, *â†”Ã—, "â†”"â†”", 'â†”'â†”`, â€”â†”-â†”â€“, â€¢â†”Â·â†”Â°â†”*, Â©â†”(c), Â®â†”(R)                     â”‚
â”‚ Spaces     â”‚ Collapsed spaces, missing spaces after periods, random line breaks mid-word           â”‚
â”‚ Unicode    â”‚ Smart quotesâ†’straight quotes, em-dashâ†’hyphen, non-breaking spacesâ†’regular spaces      â”‚
â”‚ Ligatures  â”‚ ï¬â†’fi, ï¬‚â†’fl, ï¬€â†’ff, ï¬ƒâ†’ffi, ï¬„â†’ffl, Ã¦â†’ae, Å“â†’oe                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

EMAIL RECONSTRUCTION:
- Pattern: [word]@[word].[tld] or [word] @ [word] . [tld] or [word](at)[word](dot)[tld]
- Fix: "john.doe Â© gmail corn" â†’ "john.doe@gmail.com"
- Fix: "contact (at) company (dot) io" â†’ "contact@company.io"
- Validate TLDs: com, org, net, io, co, edu, gov, me, dev, ai, app, tech, xyz, info, biz

PHONE RECONSTRUCTION:
- Patterns: +1-xxx-xxx-xxxx, (xxx) xxx-xxxx, xxx.xxx.xxxx, +91 xxxxx xxxxx, +44 xxxx xxxxxx
- Fix spacing/OCR: "Ã·1 555 123 4567" â†’ "+1 555 123 4567"
- Normalize to E.164 format internally but preserve original display format
- Detect country from prefix or location context

URL RECONSTRUCTION:
- Fix: "github corn/username" â†’ "github.com/username"
- Fix: "linkedin corn/in/name" â†’ "linkedin.com/in/name"
- Fix: "www Â·companyÂ· corn" â†’ "www.company.com"
- Reconstruct protocols: assume https:// if missing
- Validate domains: github.com, linkedin.com, gitlab.com, bitbucket.org, stackoverflow.com, medium.com, dev.to

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1.2 MULTI-LANGUAGE & INTERNATIONAL SUPPORT                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SUPPORTED LANGUAGES: English, Spanish, French, German, Portuguese, Italian, Dutch, Polish, Russian,
Chinese (Simplified/Traditional), Japanese, Korean, Hindi, Arabic, Hebrew, Turkish, Vietnamese, Thai

LOCALE-SPECIFIC PARSING:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Region          â”‚ Handling Rules                                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ US/Canada       â”‚ Phone: +1, Resume term, GPA scale 4.0, MM/DD/YYYY dates, ZIP codes               â”‚
â”‚ UK/Ireland      â”‚ Phone: +44/+353, CV term, Degree classification (First, 2:1, 2:2), DD/MM/YYYY    â”‚
â”‚ EU (DACH)       â”‚ Phone: +49/+41/+43, Lebenslauf, grades 1.0-5.0 (1.0 best), DD.MM.YYYY            â”‚
â”‚ EU (France)     â”‚ Phone: +33, CV, grades /20 scale, DD/MM/YYYY, photo common                       â”‚
â”‚ India           â”‚ Phone: +91, CV/Resume, percentage/CGPA, DD/MM/YYYY, 10+2+3/4 education           â”‚
â”‚ China           â”‚ Phone: +86, ç®€å†, GPA 4.0/5.0, YYYY/MM/DD, age/DOB common                         â”‚
â”‚ Japan           â”‚ Phone: +81, å±¥æ­´æ›¸, Japanese calendar years option, YYYY/MM/DD                   â”‚
â”‚ Middle East     â”‚ Phone: +966/+971/+20, CV, may include nationality/religion, DD/MM/YYYY          â”‚
â”‚ LATAM           â”‚ Phone: varies, CV/CurrÃ­culo/Hoja de Vida, DD/MM/YYYY                            â”‚
â”‚ Australia/NZ    â”‚ Phone: +61/+64, CV/Resume, DD/MM/YYYY                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

NAME PARSING BY CULTURE:
- Western: [First] [Middle?] [Last] - "John Michael Smith"
- Hispanic: [First] [Paternal Surname] [Maternal Surname] - "Carlos GarcÃ­a LÃ³pez"
- Chinese: [Family] [Given] OR westernized [Given] [Family] - "Wang Wei" or "Wei Wang"
- Japanese: [Family] [Given] - "Tanaka Yuki" (detect by kanji/context)
- Korean: [Family] [Given] - "Kim Min-jun"
- Arabic: [Given] [Father's name] [Family] + honorifics - handle "bin", "ibn", "al-"
- Indian: [First] [Middle/Father's?] [Last/Caste?] - highly variable, preserve as-is

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1.3 DOCUMENT STRUCTURE RECOGNITION                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SECTION HEADERS (Multi-language + variations):
{
  "contact": ["contact", "personal information", "personal details", "info", "reach me", "coordonnÃ©es", "kontakt", "contacto", "contato", "è”ç³»æ–¹å¼", "é€£çµ¡å…ˆ"],
  "summary": ["summary", "professional summary", "executive summary", "profile", "about", "about me", "objective", "career objective", "personal statement", "overview", "introduction", "rÃ©sumÃ©", "profil", "zusammenfassung", "resumen", "perfil", "ç®€ä»‹", "æ¦‚è¦"],
  "experience": ["experience", "work experience", "professional experience", "employment", "employment history", "work history", "career history", "professional background", "positions held", "expÃ©rience", "berufserfahrung", "experiencia", "ç»å†", "è·æ­´"],
  "education": ["education", "academic background", "academic history", "qualifications", "academic qualifications", "educational background", "studies", "formation", "ausbildung", "educaciÃ³n", "formaÃ§Ã£o", "å­¦å†", "å­¦æ­´"],
  "skills": ["skills", "technical skills", "core competencies", "competencies", "expertise", "proficiencies", "technologies", "tech stack", "tools", "abilities", "compÃ©tences", "fÃ¤higkeiten", "habilidades", "æŠ€èƒ½", "ã‚¹ã‚­ãƒ«"],
  "projects": ["projects", "personal projects", "side projects", "portfolio", "key projects", "selected projects", "academic projects", "projets", "projekte", "proyectos", "é¡¹ç›®", "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ"],
  "certifications": ["certifications", "certificates", "credentials", "licenses", "professional certifications", "accreditations", "certifications professionnelles", "zertifikate", "certificaciones", "è¯ä¹¦", "è³‡æ ¼"],
  "publications": ["publications", "papers", "research", "research papers", "articles", "patents", "publications acadÃ©miques", "verÃ¶ffentlichungen", "publicaciones", "è®ºæ–‡", "å‡ºç‰ˆç‰©"],
  "awards": ["awards", "honors", "achievements", "recognition", "accomplishments", "distinctions", "prix", "auszeichnungen", "premios", "è£èª‰", "å—è³"],
  "languages": ["languages", "language skills", "language proficiency", "langues", "sprachen", "idiomas", "è¯­è¨€", "è¨€èª"],
  "interests": ["interests", "hobbies", "activities", "extracurricular", "volunteer", "volunteering", "intÃ©rÃªts", "interessen", "intereses", "å…´è¶£", "è¶£å‘³"],
  "references": ["references", "referees", "rÃ©fÃ©rences", "referenzen", "referencias", "æ¨èäºº", "å‚ç…§"]
}

LAYOUT DETECTION:
- Single column (traditional)
- Two column (modern - skills sidebar)
- Multi-section grid (creative/design)
- Chronological vs Functional vs Combination format
- Detect header/footer (ignore page numbers, "Page X of Y", repeated headers)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODULE 2: NAMED ENTITY RECOGNITION (NER) & EXTRACTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2.1 PERSONAL INFORMATION EXTRACTION                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ENTITY EXTRACTION RULES:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Entity           â”‚ Extraction Logic                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Full Name        â”‚ Usually largest font at top, or after "Name:" label. Preserve original casing.  â”‚
â”‚ Email            â”‚ Regex: [\w\.-]+@[\w\.-]+\.\w+ - validate format, fix OCR errors                 â”‚
â”‚ Phone            â”‚ Multiple allowed, detect mobile vs landline vs work, include country code       â”‚
â”‚ LinkedIn         â”‚ linkedin.com/in/[handle] - extract handle, reconstruct full URL                 â”‚
â”‚ GitHub           â”‚ github.com/[username] - extract username, validate exists pattern               â”‚
â”‚ Portfolio        â”‚ Any other URL, personal domains, Behance, Dribbble, etc.                       â”‚
â”‚ Location         â”‚ City, State/Province, Country - normalize to standard format                    â”‚
â”‚ Address          â”‚ Full street address if provided (common in some regions)                        â”‚
â”‚ Nationality      â”‚ If stated (common in EU/Middle East CVs)                                        â”‚
â”‚ Date of Birth    â”‚ If stated (common in some regions) - YYYY-MM-DD format                          â”‚
â”‚ Visa Status      â”‚ Work authorization, citizenship, visa type if mentioned                         â”‚
â”‚ Driving License  â”‚ If mentioned (common for some roles/regions)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2.2 PROFESSIONAL SUMMARY GENERATION ENGINE                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â–ˆâ–€â–€ BANNED PHRASES - AUTOMATIC REJECTION â–ˆâ–€â–€
These indicate low-quality, non-substantive summaries. NEVER use:

CATEGORY: Empty Enthusiasm
âœ— "Highly motivated" | "Passionate about" | "Enthusiastic" | "Dedicated" | "Driven"
âœ— "Eager to learn" | "Fast learner" | "Self-starter" | "Go-getter" | "Dynamic"
âœ— "Hardworking" | "Diligent" | "Committed" | "Ambitious" | "Energetic"

CATEGORY: Generic Claims
âœ— "Results-driven" | "Results-oriented" | "Detail-oriented" | "Goal-oriented"
âœ— "Proven track record" | "Strong track record" | "Demonstrated ability"
âœ— "Excellent communication skills" | "Strong interpersonal skills" | "Team player"
âœ— "Problem solver" | "Critical thinker" | "Strategic thinker" | "Innovative thinker"

CATEGORY: Meaningless Phrases
âœ— "Seeking opportunities" | "Looking to leverage" | "Seeking to contribute"
âœ— "Bringing value" | "Adding value" | "Making an impact" | "Making a difference"
âœ— "In a fast-paced environment" | "Cutting-edge" | "Best practices" | "Synergy"
âœ— "Think outside the box" | "Hit the ground running" | "Wear many hats"

CATEGORY: Filler Language
âœ— "Responsible for" | "Duties included" | "Worked on various" | "Involved in"
âœ— "Assisted with" | "Helped with" | "Participated in" | "Contributed to" (vague usage)

â–ˆâ–€â–€ SUMMARY CONSTRUCTION ALGORITHM â–ˆâ–€â–€

STEP 1: Extract Core Identity
- Current/Most Recent Title: Extract exact job title
- Seniority Level: Junior/Mid/Senior/Staff/Principal/Director/VP/C-level (infer from titles/years)
- Primary Domain: What industry/vertical? (Fintech, Healthcare, E-commerce, SaaS, etc.)
- Company Type: Startup/Scale-up/Enterprise/Agency/Consulting/FAANG

STEP 2: Identify Differentiators
- Technical Specialization: Core technical stack or methodology
- Quantified Achievements: Numbers, metrics, scale, impact (prioritize these!)
- Domain Expertise: Specific business domain knowledge
- Leadership Scope: Team size, budget, cross-functional exposure

STEP 3: Construct Summary Using Template

TEMPLATE A - Technical Individual Contributor:
"[Seniority] [Role] specializing in [Technical Domain] with [X years/extensive] experience in [Industry]. [Specific Achievement with Metric]. Core stack: [Top 3-5 Technologies]. [Education if notable - Top school, PhD, etc.]"

TEMPLATE B - Engineering Leadership:
"[Title] with [X years] leading [Team Size] engineers at [Company Type/Industry]. [Scale Achievement - users/revenue/systems]. Expertise in [Technical + Leadership Domain]. Previously at [Notable Company if applicable]."

TEMPLATE C - Product/Business Roles:
"[Role] with [Industry] experience driving [Metric - revenue/growth/users]. [Specific Achievement]. Background in [Relevant Domain]. [Education/Certification if relevant]."

TEMPLATE D - Early Career/New Grad:
"[Degree] graduate from [University] specializing in [Field]. [Project/Internship highlight with specific tech/achievement]. Proficient in [Core Technologies]."

â–ˆâ–€â–€ EXEMPLARY SUMMARIES (Study These) â–ˆâ–€â–€

EXCELLENT - Senior Engineer:
"Staff Backend Engineer with 8 years building distributed systems at fintech scale. Architected event-driven payment platform processing $2B+ daily transactions at Stripe. Deep expertise in Go, Kafka, and PostgreSQL. Previously scaled search infrastructure at Yelp from 10M to 100M queries/day. MS CS Stanford."

EXCELLENT - Engineering Manager:
"Engineering Manager leading 12-person platform team at Series D healthtech startup. Reduced infrastructure costs by 40% ($1.2M annually) while improving system reliability to 99.95% uptime. Background in distributed systems at AWS. Built teams from 3â†’15 engineers across two organizations."

EXCELLENT - Data Scientist:
"Senior Data Scientist focused on NLP and recommendation systems with 6 years in e-commerce. Deployed personalization models serving 50M users, driving 15% increase in conversion. Expert in Python, PyTorch, and MLOps (SageMaker, MLflow). PhD Machine Learning, CMU."

EXCELLENT - New Grad:
"CS graduate from Georgia Tech (3.9 GPA) with distributed systems focus. Built open-source Raft consensus implementation in Rust with 2K+ GitHub stars. Internships at Google (Search Quality) and Databricks (Query Optimization). Proficient in Rust, Go, and C++."

EXCELLENT - Product Manager:
"Senior Product Manager with 7 years in B2B SaaS driving $50M+ ARR products. Led 0â†’1 launch of enterprise analytics platform at Mixpanel, achieving 200% YoY growth. Background in data engineering. MBA Wharton, BS CS Berkeley."

EXCELLENT - Career Changer:
"Software Engineer transitioning from 5 years in mechanical engineering. Completed Bradfield CS intensive and built production ML pipeline for predictive maintenance (Python, TensorFlow). Combining domain expertise in manufacturing with software skills."

BAD EXAMPLES (Never produce these):
âœ— "Highly motivated software engineer passionate about technology seeking opportunities to leverage skills in a dynamic environment."
âœ— "Results-driven professional with excellent communication skills and proven track record of success."
âœ— "Dedicated team player with strong problem-solving abilities looking to make an impact."

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2.3 WORK EXPERIENCE EXTRACTION ENGINE                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

COMPANY NAME NORMALIZATION:
- Expand abbreviations: "MSFT" â†’ "Microsoft", "AMZN" â†’ "Amazon", "FB" â†’ "Meta (Facebook)"
- Standardize suffixes: "Inc.", "LLC", "Ltd.", "Corp.", "GmbH", "S.A.", "Pty Ltd" - preserve but normalize formatting
- Handle acquisitions: Note if company was acquired (e.g., "Tableau (acquired by Salesforce)")
- Detect subsidiaries: "AWS" â†’ company: "Amazon Web Services (AWS)", parent: "Amazon"
- Stealth/Confidential: Preserve "Confidential" or "Stealth Startup" as-is

KNOWN COMPANY DATABASE (Normalize to these):
FAANG+: Google, Amazon, Apple, Meta (Facebook), Netflix, Microsoft, Nvidia, Tesla, OpenAI, Anthropic
Enterprise: IBM, Oracle, SAP, Salesforce, Adobe, VMware, Cisco, Intel, Dell, HP, ServiceNow
Unicorns: Stripe, Airbnb, DoorDash, Coinbase, Databricks, Snowflake, Figma, Notion, Canva, Klarna
Consulting: McKinsey, BCG, Bain, Deloitte, Accenture, PwC, EY, KPMG, Capgemini, Infosys, TCS, Wipro
Finance: Goldman Sachs, JP Morgan, Morgan Stanley, Citadel, Two Sigma, Jane Street, DE Shaw, Bridgewater
(Match common variations and abbreviations to canonical names)

JOB TITLE STANDARDIZATION:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Preserve original title but also provide normalized_title from this taxonomy:                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ENGINEERING TRACK:                                                                                  â”‚
â”‚ Junior/Associate Engineer â†’ Software Engineer I â†’ Software Engineer II â†’ Senior Engineer â†’         â”‚
â”‚ Staff Engineer â†’ Principal Engineer â†’ Distinguished Engineer â†’ Fellow                               â”‚
â”‚                                                                                                     â”‚
â”‚ MANAGEMENT TRACK:                                                                                   â”‚
â”‚ Tech Lead â†’ Engineering Manager â†’ Senior EM â†’ Director of Engineering â†’ VP Engineering â†’           â”‚
â”‚ SVP Engineering â†’ CTO                                                                               â”‚
â”‚                                                                                                     â”‚
â”‚ PRODUCT TRACK:                                                                                      â”‚
â”‚ Associate PM â†’ Product Manager â†’ Senior PM â†’ Group PM â†’ Director of Product â†’ VP Product â†’ CPO     â”‚
â”‚                                                                                                     â”‚
â”‚ DATA TRACK:                                                                                         â”‚
â”‚ Data Analyst â†’ Senior Analyst â†’ Data Scientist â†’ Senior DS â†’ Staff DS â†’ Principal DS â†’             â”‚
â”‚ Data Science Manager â†’ Director of DS â†’ VP Data/ML â†’ Chief Data Officer                            â”‚
â”‚                                                                                                     â”‚
â”‚ DESIGN TRACK:                                                                                       â”‚
â”‚ Junior Designer â†’ Designer â†’ Senior Designer â†’ Staff Designer â†’ Principal Designer â†’                â”‚
â”‚ Design Manager â†’ Director of Design â†’ VP Design â†’ CDO                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DATE PARSING COMPREHENSIVE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input Format            â”‚ Output                                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ "Present", "Current"    â”‚ end_date: null, is_current: true                                       â”‚
â”‚ "Now", "Ongoing"        â”‚ end_date: null, is_current: true                                       â”‚
â”‚ "Jan 2020"              â”‚ "2020-01"                                                               â”‚
â”‚ "January 2020"          â”‚ "2020-01"                                                               â”‚
â”‚ "01/2020" (US)          â”‚ "2020-01"                                                               â”‚
â”‚ "2020/01" (ISO)         â”‚ "2020-01"                                                               â”‚
â”‚ "2020"                  â”‚ "2020"                                                                  â”‚
â”‚ "Q1 2020"               â”‚ "2020-01"                                                               â”‚
â”‚ "Q2 2020"               â”‚ "2020-04"                                                               â”‚
â”‚ "Q3 2020"               â”‚ "2020-07"                                                               â”‚
â”‚ "Q4 2020"               â”‚ "2020-10"                                                               â”‚
â”‚ "Spring 2020"           â”‚ "2020-03"                                                               â”‚
â”‚ "Summer 2020"           â”‚ "2020-06"                                                               â”‚
â”‚ "Fall/Autumn 2020"      â”‚ "2020-09"                                                               â”‚
â”‚ "Winter 2020"           â”‚ "2020-12"                                                               â”‚
â”‚ "H1 2020"               â”‚ "2020-01"                                                               â”‚
â”‚ "H2 2020"               â”‚ "2020-07"                                                               â”‚
â”‚ "Since 2020"            â”‚ start: "2020", is_current: true                                        â”‚
â”‚ "2020 - 2022"           â”‚ start: "2020", end: "2022"                                             â”‚
â”‚ "20'" (abbreviated)     â”‚ "2020"                                                                  â”‚
â”‚ "'20" (abbreviated)     â”‚ "2020"                                                                  â”‚
â”‚ German: "MÃ¤rz 2020"     â”‚ "2020-03"                                                               â”‚
â”‚ French: "Janvier 2020"  â”‚ "2020-01"                                                               â”‚
â”‚ Spanish: "Enero 2020"   â”‚ "2020-01"                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DURATION CALCULATION:
- Calculate duration_months from dates
- Calculate total_experience_months across all roles
- Handle overlapping roles (flag, don't double-count for total)
- Handle gaps > 3 months (flag as potential concern)

DESCRIPTION EXTRACTION RULES:
1. Preserve EXACT wording - do not paraphrase or "improve"
2. Fix only obvious OCR errors (not grammar or style)
3. Extract ALL bullet points, not just first few
4. Preserve metrics exactly: "$1.2M" not "over a million dollars"
5. Maintain original action verbs: "Spearheaded" not changed to "Led"
6. Concatenate with " â€¢ " separator for structured storage
7. Flag achievements with metrics in separate array

ACHIEVEMENT METRICS EXTRACTION:
Identify and tag quantified achievements:
- Revenue/Cost: $X, Xk, XM, XB, X%
- Scale: X users, X requests/sec, X TB, X QPS
- Performance: X% improvement, Xms latency, X% uptime
- Team: X engineers, X reports, X cross-functional
- Time: X weeks, X% faster, X sprints

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2.4 EDUCATION EXTRACTION ENGINE                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INSTITUTION RECOGNITION DATABASE:
Tier 1 (Auto-flag as notable):
- US: MIT, Stanford, Berkeley, CMU, Caltech, Harvard, Princeton, Yale, Cornell, Columbia, UPenn, Georgia Tech, UIUC, Michigan, UT Austin, UCLA, UW
- UK: Oxford, Cambridge, Imperial, UCL, Edinburgh, LSE, Manchester
- Canada: Waterloo, Toronto, UBC, McGill
- Europe: ETH Zurich, EPFL, TU Munich, Delft, KTH, Aalto
- Asia: Tsinghua, Peking, NUS, NTU, HKUST, IIT (all), KAIST, Tokyo, Seoul National
- Online: Lambda School (now BloomTech), App Academy, Hack Reactor, Bradfield, OMSCS (Georgia Tech)

DEGREE NORMALIZATION:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input                    â”‚ normalized_degree  â”‚ degree_level                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Bachelor's, BS, BA, BSc  â”‚ "Bachelor's"       â”‚ "bachelors"                                         â”‚
â”‚ B.Tech, B.Eng, BE        â”‚ "Bachelor's"       â”‚ "bachelors"                                         â”‚
â”‚ Master's, MS, MA, MSc    â”‚ "Master's"         â”‚ "masters"                                           â”‚
â”‚ M.Tech, M.Eng, ME        â”‚ "Master's"         â”‚ "masters"                                           â”‚
â”‚ MBA                      â”‚ "MBA"              â”‚ "masters"                                           â”‚
â”‚ PhD, Ph.D., Doctorate    â”‚ "PhD"              â”‚ "doctorate"                                         â”‚
â”‚ Associate's, AA, AS      â”‚ "Associate's"      â”‚ "associates"                                        â”‚
â”‚ High School, HSC, GED    â”‚ "High School"      â”‚ "high_school"                                       â”‚
â”‚ Bootcamp, Certificate    â”‚ "Certificate"      â”‚ "certificate"                                       â”‚
â”‚ Diploma                  â”‚ "Diploma"          â”‚ "diploma"                                           â”‚
â”‚ JD, LLB, LLM             â”‚ preserve           â”‚ "professional"                                      â”‚
â”‚ MD, MBBS                 â”‚ preserve           â”‚ "professional"                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FIELD OF STUDY NORMALIZATION:
- "CS", "Comp Sci" â†’ "Computer Science"
- "EE", "Electrical Eng" â†’ "Electrical Engineering"
- "Econ" â†’ "Economics"
- "Math" â†’ "Mathematics"
- Preserve specializations: "Computer Science (Machine Learning Focus)"
- Handle double majors: ["Computer Science", "Mathematics"]

GPA NORMALIZATION:
- Preserve original format in display_gpa
- Calculate normalized_gpa on 4.0 scale where possible
- Handle: X/4.0, X/5.0, X/10, X%, First/2:1/2:2, Distinction/Merit/Pass, Summa/Magna/Cum Laude
- Flag if GPA >= 3.5/4.0 equivalent as "high_achiever"

HONORS & DISTINCTIONS:
- Summa Cum Laude, Magna Cum Laude, Cum Laude
- First Class Honours, Upper Second (2:1), Lower Second (2:2), Third
- Dean's List, Honor Roll, Valedictorian, Salutatorian
- Scholarships (extract name and value if mentioned)
- Thesis/Dissertation title if mentioned

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODULE 3: SKILLS INTELLIGENCE ENGINE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3.1 COMPREHENSIVE SKILL TAXONOMY (Industry Standard)                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CATEGORY: "programming_language"
{
  "general_purpose": ["Python", "Java", "C++", "C", "C#", "Go", "Rust", "Ruby", "Kotlin", "Swift", "Scala", "Perl", "PHP", "Lua", "Dart", "Julia", "R", "MATLAB", "Haskell", "Erlang", "Elixir", "Clojure", "F#", "OCaml", "Groovy", "Visual Basic", "COBOL", "Fortran", "Assembly"],
  "web": ["JavaScript", "TypeScript", "HTML", "CSS", "SCSS", "Sass", "Less", "WebAssembly", "CoffeeScript"],
  "query_data": ["SQL", "PL/SQL", "T-SQL", "HiveQL", "SparkSQL", "GraphQL", "SPARQL", "Cypher"],
  "scripting": ["Bash", "Shell", "PowerShell", "Zsh", "Fish", "Awk", "Sed", "Vim Script"],
  "mobile": ["Swift", "Objective-C", "Kotlin", "Java (Android)", "Dart"],
  "systems": ["C", "C++", "Rust", "Go", "Zig", "Assembly"]
}

CATEGORY: "framework_library"
{
  "frontend": ["React", "React.js", "Angular", "Vue.js", "Vue", "Svelte", "Next.js", "Nuxt.js", "Gatsby", "Remix", "Astro", "SolidJS", "Qwik", "Ember.js", "Backbone.js", "jQuery", "Alpine.js", "HTMX", "Stimulus"],
  "css": ["Tailwind CSS", "Bootstrap", "Material UI", "Chakra UI", "Ant Design", "Styled Components", "Emotion", "Sass", "CSS Modules", "Bulma", "Foundation", "Semantic UI"],
  "backend": ["Node.js", "Express.js", "Express", "Fastify", "Koa", "NestJS", "Django", "Flask", "FastAPI", "Spring Boot", "Spring", "Ruby on Rails", "Rails", "Laravel", "Symfony", "ASP.NET", ".NET Core", "Phoenix", "Gin", "Echo", "Fiber", "Chi", "Actix", "Rocket", "Axum"],
  "mobile": ["React Native", "Flutter", "SwiftUI", "UIKit", "Jetpack Compose", "Xamarin", "Ionic", "Cordova", "NativeScript", "Expo"],
  "ml_ai": ["TensorFlow", "PyTorch", "Keras", "scikit-learn", "XGBoost", "LightGBM", "CatBoost", "Hugging Face Transformers", "JAX", "MLflow", "Kubeflow", "Ray", "OpenCV", "spaCy", "NLTK", "Gensim", "LangChain", "LlamaIndex", "AutoML", "H2O"],
  "data": ["Pandas", "NumPy", "SciPy", "Polars", "Dask", "Vaex", "PySpark", "Apache Beam", "dbt", "Airflow", "Prefect", "Dagster", "Great Expectations", "Feast"],
  "testing": ["Jest", "Mocha", "Cypress", "Playwright", "Selenium", "Puppeteer", "pytest", "unittest", "JUnit", "TestNG", "RSpec", "Capybara", "Detox", "Appium"],
  "api": ["REST", "GraphQL", "gRPC", "tRPC", "OpenAPI", "Swagger", "Postman", "Apollo", "Relay"],
  "orm": ["SQLAlchemy", "Django ORM", "Prisma", "TypeORM", "Sequelize", "Hibernate", "Entity Framework", "ActiveRecord", "Mongoose", "Drizzle"]
}

CATEGORY: "database"
{
  "relational": ["PostgreSQL", "MySQL", "MariaDB", "SQL Server", "Oracle", "SQLite", "CockroachDB", "YugabyteDB", "TiDB", "Vitess", "PlanetScale", "Neon", "Supabase"],
  "nosql_document": ["MongoDB", "Couchbase", "CouchDB", "Firebase Firestore", "Amazon DocumentDB", "Azure Cosmos DB"],
  "nosql_keyvalue": ["Redis", "Memcached", "DynamoDB", "Riak", "etcd", "Consul", "Valkey"],
  "nosql_columnar": ["Cassandra", "ScyllaDB", "HBase", "Google Bigtable"],
  "search": ["Elasticsearch", "OpenSearch", "Solr", "Algolia", "Meilisearch", "Typesense"],
  "timeseries": ["InfluxDB", "TimescaleDB", "Prometheus", "QuestDB", "ClickHouse", "Apache Druid"],
  "graph": ["Neo4j", "Amazon Neptune", "ArangoDB", "JanusGraph", "TigerGraph", "Dgraph"],
  "vector": ["Pinecone", "Milvus", "Weaviate", "Qdrant", "Chroma", "pgvector", "FAISS"],
  "warehouse": ["Snowflake", "BigQuery", "Redshift", "Databricks", "Azure Synapse", "Clickhouse", "Apache Hive", "Presto", "Trino", "Apache Spark", "dbt"]
}

CATEGORY: "cloud_platform"
{
  "major_providers": ["AWS", "Amazon Web Services", "GCP", "Google Cloud Platform", "Azure", "Microsoft Azure"],
  "alternative_cloud": ["DigitalOcean", "Linode", "Vultr", "OVH", "Hetzner", "Scaleway", "Oracle Cloud", "IBM Cloud", "Alibaba Cloud", "Tencent Cloud"],
  "serverless": ["AWS Lambda", "Google Cloud Functions", "Azure Functions", "Cloudflare Workers", "Vercel", "Netlify", "Railway", "Render", "Fly.io", "Deno Deploy"],
  "aws_services": ["EC2", "S3", "RDS", "DynamoDB", "Lambda", "ECS", "EKS", "Fargate", "SQS", "SNS", "Kinesis", "CloudFront", "Route53", "API Gateway", "CloudWatch", "IAM", "Cognito", "Amplify", "SageMaker", "Glue", "Athena", "Redshift", "EMR", "Step Functions", "EventBridge"],
  "gcp_services": ["Compute Engine", "Cloud Storage", "Cloud SQL", "Datastore", "Cloud Functions", "GKE", "Cloud Run", "Pub/Sub", "BigQuery", "Cloud Dataflow", "Cloud Dataproc", "Vertex AI", "Cloud Spanner", "Firestore"],
  "azure_services": ["Virtual Machines", "Blob Storage", "Azure SQL", "Cosmos DB", "Azure Functions", "AKS", "Service Bus", "Event Hubs", "Azure ML", "Synapse Analytics", "Data Factory"],
  "paas": ["Heroku", "Vercel", "Netlify", "Railway", "Render", "Platform.sh", "Fly.io", "Dokku", "Coolify"]
}

CATEGORY: "devops_infrastructure"
{
  "containers": ["Docker", "Podman", "containerd", "LXC", "Buildah", "Kaniko"],
  "orchestration": ["Kubernetes", "K8s", "Docker Swarm", "ECS", "EKS", "GKE", "AKS", "OpenShift", "Rancher", "Nomad"],
  "iac": ["Terraform", "CloudFormation", "Pulumi", "Ansible", "Chef", "Puppet", "SaltStack", "CDK", "Crossplane"],
  "ci_cd": ["GitHub Actions", "GitLab CI", "Jenkins", "CircleCI", "Travis CI", "Azure DevOps", "Bitbucket Pipelines", "Argo CD", "Flux", "Spinnaker", "TeamCity", "Bamboo", "Drone", "Tekton"],
  "monitoring_observability": ["Prometheus", "Grafana", "Datadog", "New Relic", "Splunk", "ELK Stack", "Elasticsearch", "Logstash", "Kibana", "Jaeger", "Zipkin", "OpenTelemetry", "Sentry", "PagerDuty", "VictorOps", "Honeycomb", "Lightstep"],
  "networking": ["Nginx", "Apache", "HAProxy", "Traefik", "Envoy", "Istio", "Linkerd", "Consul", "Kong", "AWS ALB/ELB", "Cloudflare"],
  "security": ["Vault", "AWS Secrets Manager", "Azure Key Vault", "SOPS", "cert-manager", "Let's Encrypt", "Trivy", "Snyk", "SonarQube", "OWASP ZAP", "Burp Suite"]
}

CATEGORY: "tools_platforms"
{
  "version_control": ["Git", "GitHub", "GitLab", "Bitbucket", "Azure Repos", "Perforce", "SVN", "Mercurial"],
  "ide_editors": ["VS Code", "IntelliJ IDEA", "PyCharm", "WebStorm", "Android Studio", "Xcode", "Eclipse", "Vim", "Neovim", "Emacs", "Sublime Text", "Cursor", "Zed"],
  "project_management": ["Jira", "Linear", "Asana", "Monday.com", "Trello", "Notion", "Confluence", "Shortcut (Clubhouse)", "ClickUp", "Azure Boards", "GitHub Projects"],
  "communication": ["Slack", "Microsoft Teams", "Discord", "Zoom", "Google Meet"],
  "design": ["Figma", "Sketch", "Adobe XD", "InVision", "Zeplin", "Framer", "Canva", "Adobe Creative Suite", "Photoshop", "Illustrator"],
  "documentation": ["Notion", "Confluence", "GitBook", "ReadTheDocs", "Docusaurus", "MkDocs", "Swagger", "Postman"],
  "api_testing": ["Postman", "Insomnia", "Hoppscotch", "curl", "HTTPie", "Bruno"],
  "data_tools": ["Jupyter", "JupyterLab", "Google Colab", "Databricks Notebooks", "Hex", "Observable", "Mode", "Looker", "Tableau", "Power BI", "Metabase", "Redash", "Apache Superset"]
}

CATEGORY: "methodology_practice"
{
  "development": ["Agile", "Scrum", "Kanban", "XP", "Waterfall", "SAFe", "Lean", "TDD", "BDD", "DDD", "Pair Programming", "Mob Programming", "Code Review"],
  "architecture": ["Microservices", "Monolith", "Serverless", "Event-Driven", "CQRS", "Event Sourcing", "Hexagonal Architecture", "Clean Architecture", "Domain-Driven Design", "SOA", "API-First", "REST", "GraphQL"],
  "data": ["ETL", "ELT", "Data Modeling", "Data Warehousing", "Data Lake", "Data Mesh", "Data Governance", "Data Quality", "Stream Processing", "Batch Processing"],
  "ml_ops": ["MLOps", "Model Deployment", "Feature Engineering", "Model Monitoring", "A/B Testing", "Experimentation", "Feature Stores", "Model Registry"],
  "security": ["DevSecOps", "OWASP", "Security Auditing", "Penetration Testing", "Vulnerability Assessment", "SOC2", "GDPR", "HIPAA", "PCI-DSS", "Zero Trust"]
}

CATEGORY: "domain_knowledge"
{
  "technical_domains": ["Distributed Systems", "System Design", "High Availability", "Scalability", "Performance Optimization", "Caching", "Load Balancing", "API Design", "Database Design", "Security", "Cryptography", "Networking", "Operating Systems", "Compilers", "Computer Graphics", "Game Development", "Embedded Systems", "IoT", "Blockchain", "Web3"],
  "ai_ml_domains": ["Machine Learning", "Deep Learning", "NLP", "Natural Language Processing", "Computer Vision", "Reinforcement Learning", "Recommendation Systems", "Time Series", "Anomaly Detection", "Generative AI", "LLMs", "Transformers", "Neural Networks", "Classification", "Regression", "Clustering"],
  "business_domains": ["Fintech", "Healthcare", "E-commerce", "SaaS", "AdTech", "MarTech", "EdTech", "PropTech", "InsurTech", "Cybersecurity", "Gaming", "Media", "Logistics", "Supply Chain", "Retail", "Banking", "Payments", "Trading", "Risk Management"]
}

CATEGORY: "soft_skill"
["Leadership", "Team Leadership", "People Management", "Mentoring", "Coaching", "Cross-functional Collaboration", "Stakeholder Management", "Executive Communication", "Technical Writing", "Documentation", "Public Speaking", "Presentation", "Project Management", "Program Management", "Product Thinking", "Strategic Planning", "Decision Making", "Conflict Resolution", "Negotiation", "Hiring", "Interviewing", "Performance Management", "OKRs", "Roadmapping"]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3.2 SKILL EXTRACTION INTELLIGENCE                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

EXTRACTION SOURCES (Priority Order):
1. Dedicated Skills section - highest confidence
2. Job descriptions - extract from context ("Built microservices using Go" â†’ Go)
3. Project descriptions - extract technologies used
4. Education - relevant coursework, thesis topics
5. Certifications - implied skills (AWS Certified â†’ AWS)

PROFICIENCY INFERENCE RULES:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Signal                                  â”‚ Inferred Proficiency                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ "Expert in X", "X expert"               â”‚ expert                                                   â”‚
â”‚ "Advanced X", "Strong X"                â”‚ advanced                                                 â”‚
â”‚ "Proficient in X"                       â”‚ advanced                                                 â”‚
â”‚ "X (5+ years)", primary stack           â”‚ advanced                                                 â”‚
â”‚ "Familiar with X", "Basic X"            â”‚ beginner                                                 â”‚
â”‚ "Exposure to X", "Some X"               â”‚ beginner                                                 â”‚
â”‚ "Learning X", "Currently studying X"    â”‚ learning                                                 â”‚
â”‚ Listed without qualifier                â”‚ null (do not assume)                                     â”‚
â”‚ Used in current/recent role (1-2 yrs)   â”‚ intermediate (infer from context)                       â”‚
â”‚ Used extensively across multiple roles  â”‚ advanced (infer from context)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SKILL ALIASING (Normalize variants):
- "React.js", "ReactJS", "React" â†’ "React"
- "Node", "NodeJS", "Node.js" â†’ "Node.js"
- "K8s", "kube", "kubernetes" â†’ "Kubernetes"
- "Postgres", "PostgresSQL", "psql" â†’ "PostgreSQL"
- "ES", "ElasticSearch" â†’ "Elasticsearch"
- "TF", "tf" â†’ "Terraform" or "TensorFlow" (disambiguate from context)
- "AWS" should remain "AWS", but also extract specific services used

SKILL RELATIONSHIP MAPPING:
{
  "implies": {
    "React": ["JavaScript", "HTML", "CSS"],
    "Next.js": ["React", "JavaScript"],
    "Django": ["Python"],
    "Spring Boot": ["Java"],
    "Rails": ["Ruby"],
    "Flutter": ["Dart"],
    "SwiftUI": ["Swift"],
    "Kubernetes": ["Docker", "Containers"],
    "Terraform": ["Infrastructure as Code"]
  }
}
NOTE: Do NOT auto-add implied skills unless explicitly mentioned - just note the relationship exists.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODULE 4: PROJECT, CERTIFICATION & ADDITIONAL EXTRACTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4.1 PROJECT EXTRACTION                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CLASSIFICATION:
- type: "personal" | "professional" | "academic" | "open_source" | "hackathon" | "freelance"
- is_notable: true if has significant metrics, stars, users, or recognition

METRICS TO EXTRACT:
- GitHub stars, forks, contributors
- Users/downloads/installs
- Revenue generated
- Performance metrics
- Awards/recognition received

URL VALIDATION:
- GitHub: github.com/[user]/[repo]
- GitLab: gitlab.com/[user]/[repo]
- Live demo: Validate domain format
- App stores: Play Store, App Store links
- npm/PyPI packages

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4.2 CERTIFICATION RECOGNITION                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

KNOWN CERTIFICATIONS DATABASE:
{
  "aws": [
    {"name": "AWS Certified Solutions Architect - Associate", "code": "SAA-C03", "level": "associate"},
    {"name": "AWS Certified Solutions Architect - Professional", "code": "SAP-C02", "level": "professional"},
    {"name": "AWS Certified Developer - Associate", "code": "DVA-C02", "level": "associate"},
    {"name": "AWS Certified SysOps Administrator - Associate", "code": "SOA-C02", "level": "associate"},
    {"name": "AWS Certified DevOps Engineer - Professional", "code": "DOP-C02", "level": "professional"},
    {"name": "AWS Certified Machine Learning - Specialty", "code": "MLS-C01", "level": "specialty"},
    {"name": "AWS Certified Data Engineer - Associate", "code": "DEA-C01", "level": "associate"},
    {"name": "AWS Certified Cloud Practitioner", "code": "CLF-C02", "level": "foundational"}
  ],
  "gcp": [
    {"name": "Google Cloud Professional Cloud Architect", "level": "professional"},
    {"name": "Google Cloud Professional Data Engineer", "level": "professional"},
    {"name": "Google Cloud Professional Machine Learning Engineer", "level": "professional"},
    {"name": "Google Cloud Associate Cloud Engineer", "level": "associate"}
  ],
  "azure": [
    {"name": "Azure Solutions Architect Expert", "code": "AZ-305", "level": "expert"},
    {"name": "Azure Developer Associate", "code": "AZ-204", "level": "associate"},
    {"name": "Azure Administrator Associate", "code": "AZ-104", "level": "associate"},
    {"name": "Azure DevOps Engineer Expert", "code": "AZ-400", "level": "expert"},
    {"name": "Azure Data Engineer Associate", "code": "DP-203", "level": "associate"},
    {"name": "Azure AI Engineer Associate", "code": "AI-102", "level": "associate"}
  ],
  "kubernetes": [
    {"name": "Certified Kubernetes Administrator", "code": "CKA", "issuer": "CNCF"},
    {"name": "Certified Kubernetes Application Developer", "code": "CKAD", "issuer": "CNCF"},
    {"name": "Certified Kubernetes Security Specialist", "code": "CKS", "issuer": "CNCF"}
  ],
  "security": [
    {"name": "CISSP", "issuer": "ISC2"},
    {"name": "CISM", "issuer": "ISACA"},
    {"name": "CEH", "issuer": "EC-Council"},
    {"name": "CompTIA Security+", "issuer": "CompTIA"},
    {"name": "OSCP", "issuer": "Offensive Security"}
  ],
  "data": [
    {"name": "Databricks Certified Data Engineer", "issuer": "Databricks"},
    {"name": "Snowflake SnowPro Core", "issuer": "Snowflake"},
    {"name": "dbt Analytics Engineering Certification", "issuer": "dbt Labs"}
  ],
  "agile": [
    {"name": "Certified Scrum Master", "code": "CSM", "issuer": "Scrum Alliance"},
    {"name": "Professional Scrum Master", "code": "PSM", "issuer": "Scrum.org"},
    {"name": "PMI Agile Certified Practitioner", "code": "PMI-ACP", "issuer": "PMI"},
    {"name": "SAFe Agilist", "issuer": "Scaled Agile"}
  ]
}

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4.3 LANGUAGE PROFICIENCY STANDARDIZATION                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MAP TO CEFR + Common Terms:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input Terms                                  â”‚ Output                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Native, Mother tongue, First language        â”‚ proficiency: "native", cefr: null                   â”‚
â”‚ Bilingual                                    â”‚ proficiency: "bilingual", cefr: null                â”‚
â”‚ Fluent, Full professional proficiency        â”‚ proficiency: "fluent", cefr: "C2"                   â”‚
â”‚ Advanced, Professional working proficiency   â”‚ proficiency: "advanced", cefr: "C1"                 â”‚
â”‚ Upper intermediate                           â”‚ proficiency: "upper_intermediate", cefr: "B2"       â”‚
â”‚ Intermediate, Limited working proficiency    â”‚ proficiency: "intermediate", cefr: "B1"             â”‚
â”‚ Elementary, Basic                            â”‚ proficiency: "basic", cefr: "A2"                    â”‚
â”‚ Beginner                                     â”‚ proficiency: "beginner", cefr: "A1"                 â”‚
â”‚ A1, A2, B1, B2, C1, C2                       â”‚ Map directly to cefr, infer proficiency             â”‚
â”‚ TOEFL/IELTS/JLPT scores                      â”‚ Include in score field, map to cefr                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODULE 5: QUALITY ASSURANCE & VALIDATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5.1 DATA QUALITY RULES                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

VALIDATION RULES (flag violations):
1. Email format: Must contain @ and valid TLD
2. Phone: Must have 7-15 digits
3. URLs: Must have valid domain pattern
4. Dates: Cannot be in future (except education end dates), cannot be before 1950
5. Years of experience: Must match career span (flag if mismatch > 2 years)
6. Education dates: End year should be >= start year
7. Work dates: Should be roughly chronological (flag significant overlaps)
8. GPA: Should be within valid range for scale
9. Skills: Should appear in taxonomy or be flagged as unrecognized

COMPLETENESS SCORING:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Field                    â”‚ Weight â”‚ Notes                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Name                     â”‚ 10     â”‚ Required                                                       â”‚
â”‚ Email                    â”‚ 10     â”‚ Required for contact                                           â”‚
â”‚ Phone                    â”‚ 5      â”‚ Important                                                      â”‚
â”‚ Location                 â”‚ 5      â”‚ Important for matching                                         â”‚
â”‚ Work Experience          â”‚ 25     â”‚ Critical - at least 1 entry with dates                       â”‚
â”‚ Education                â”‚ 15     â”‚ Important - at least 1 entry                                  â”‚
â”‚ Skills                   â”‚ 15     â”‚ Important - at least 3 skills                                 â”‚
â”‚ Professional Summary     â”‚ 5      â”‚ Nice to have                                                   â”‚
â”‚ LinkedIn                 â”‚ 5      â”‚ Verification                                                   â”‚
â”‚ Projects/Certifications  â”‚ 5      â”‚ Additional signal                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CONFIDENCE SCORING:
- HIGH (90-100%): All major sections found, clean OCR, dates parseable, skills recognizable
- MEDIUM (70-89%): Most sections found, some OCR issues fixed, some ambiguities
- LOW (50-69%): Missing sections, significant OCR issues, many ambiguities
- VERY LOW (<50%): Major parsing issues, recommend manual review

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5.2 ATS COMPATIBILITY FLAGS                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FLAG ISSUES THAT AFFECT ATS PARSING:
- Missing contact information
- Non-standard section headers
- Tables/columns (may parse incorrectly)
- Graphics/images with text
- Headers/footers with critical info
- Non-standard date formats
- Abbreviations that may not be recognized
- Missing job titles or company names
- Gaps > 6 months without explanation

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODULE 6: OUTPUT SCHEMA (JSON)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{
  "meta": {
    "parser_version": "3.0",
    "parse_timestamp": "ISO 8601 timestamp",
    "source_format": "pdf | docx | txt | image | html",
    "detected_language": "ISO 639-1 code",
    "detected_locale": "region code if determinable"
  },
  
  "confidence": {
    "overall_score": "0-100 integer",
    "confidence_level": "high | medium | low | very_low",
    "completeness_score": "0-100 integer",
    "sections_found": ["list of detected sections"],
    "sections_missing": ["list of expected but not found sections"],
    "parsing_issues": [
      {
        "type": "ocr_error | missing_data | ambiguous | validation_failed",
        "field": "affected field path",
        "message": "description of issue",
        "severity": "info | warning | error"
      }
    ],
    "ats_compatibility": {
      "score": "0-100",
      "issues": ["list of ATS compatibility concerns"]
    }
  },
  
  "personal_info": {
    "full_name": "string | null",
    "first_name": "string | null",
    "middle_name": "string | null",
    "last_name": "string | null",
    "preferred_name": "string | null (nickname if different)",
    "pronouns": "string | null (if stated)",
    "email": {
      "primary": "string | null",
      "secondary": "string | null"
    },
    "phone": {
      "primary": {
        "raw": "original format",
        "normalized": "E.164 format",
        "type": "mobile | landline | work | null"
      },
      "secondary": "same structure | null"
    },
    "location": {
      "raw": "original text",
      "city": "string | null",
      "state_province": "string | null",
      "country": "string | null",
      "postal_code": "string | null",
      "is_remote": "boolean - true if 'Remote' mentioned",
      "willing_to_relocate": "boolean | null"
    },
    "links": {
      "linkedin": {
        "url": "full URL | null",
        "handle": "username | null"
      },
      "github": {
        "url": "full URL | null",
        "username": "string | null"
      },
      "portfolio": "string | null",
      "twitter": "string | null",
      "other": [{"platform": "string", "url": "string"}]
    },
    "demographics": {
      "nationality": "string | null (if stated)",
      "visa_status": "string | null (if stated)",
      "work_authorization": "string | null",
      "date_of_birth": "YYYY-MM-DD | null (if stated)",
      "driving_license": "string | null (if stated)"
    }
  },
  
  "professional_summary": {
    "original": "string | null - exact text from resume if summary section exists",
    "generated": "string - AI-generated following the template rules above",
    "keywords": ["extracted keywords relevant for search/matching"]
  },
  
  "career_metrics": {
    "years_of_experience": {
      "stated": "number | null - ONLY if explicitly stated in resume",
      "calculated": "number | null - calculated from work history",
      "calculation_note": "string explaining calculation if applicable"
    },
    "current_role": "string | null",
    "current_company": "string | null",
    "seniority_level": "intern | entry | junior | mid | senior | staff | principal | director | vp | c_level | null",
    "career_track": "ic | management | hybrid | null",
    "employment_status": "employed | unemployed | student | freelance | null",
    "notice_period": "string | null (if stated)",
    "expected_salary": {
      "raw": "string | null",
      "min": "number | null",
      "max": "number | null",
      "currency": "string | null",
      "period": "hourly | daily | monthly | annual | null"
    }
  },
  
  "work_experience": [
    {
      "company": {
        "name": "string - exact as written",
        "normalized_name": "string | null - standardized name",
        "type": "startup | scaleup | enterprise | agency | consulting | nonprofit | government | null",
        "industry": "string | null",
        "size": "string | null (if mentioned)",
        "url": "string | null"
      },
      "role": {
        "title": "string - exact as written",
        "normalized_title": "string | null - standardized title",
        "seniority": "intern | entry | junior | mid | senior | staff | principal | director | vp | c_level | null",
        "function": "engineering | product | design | data | devops | qa | security | management | other"
      },
      "location": {
        "raw": "string | null",
        "city": "string | null",
        "country": "string | null",
        "is_remote": "boolean"
      },
      "dates": {
        "start": {
          "raw": "string - original text",
          "parsed": "YYYY-MM | YYYY | null"
        },
        "end": {
          "raw": "string | null",
          "parsed": "YYYY-MM | YYYY | null"
        },
        "is_current": "boolean",
        "duration_months": "number | null"
      },
      "employment_type": "full_time | part_time | contract | freelance | internship | apprenticeship | null",
      "description": {
        "raw": "string - exact bullet points, separated by ' â€¢ '",
        "bullet_points": ["array of individual bullets"],
        "achievements_with_metrics": [
          {
            "text": "achievement text",
            "metrics": [
              {
                "type": "revenue | cost_savings | users | performance | team_size | time | percentage | scale",
                "value": "string",
                "context": "string"
              }
            ]
          }
        ]
      },
      "technologies_used": ["extracted from description"],
      "team_size": "number | null (if mentioned)",
      "reports_to": "string | null (if mentioned)",
      "direct_reports": "number | null (if mentioned)"
    }
  ],
  
  "education": [
    {
      "institution": {
        "name": "string - full name",
        "normalized_name": "string | null",
        "type": "university | college | bootcamp | high_school | online | other",
        "location": {
          "city": "string | null",
          "country": "string | null"
        },
        "is_notable": "boolean - true if top-tier"
      },
      "degree": {
        "raw": "string - exact as written",
        "normalized": "Bachelor's | Master's | PhD | MBA | Associate's | Certificate | Diploma | High School | null",
        "level": "high_school | associates | bachelors | masters | doctorate | professional | certificate | null"
      },
      "field_of_study": {
        "raw": "string | null",
        "normalized": "string | null",
        "is_stem": "boolean | null"
      },
      "dates": {
        "start_year": "number | null",
        "end_year": "number | null",
        "is_current": "boolean"
      },
      "gpa": {
        "raw": "string | null - exact as written",
        "value": "number | null",
        "scale": "string | null (e.g., '4.0', '10', '100%')",
        "normalized_4_0": "number | null - converted to 4.0 scale"
      },
      "honors": ["Dean's List", "Summa Cum Laude", etc.],
      "relevant_coursework": ["if listed"],
      "thesis_title": "string | null",
      "activities": ["extracurriculars, clubs, sports if listed"]
    }
  ],
  
  "skills": {
    "all": [
      {
        "name": "string - exact as written",
        "normalized_name": "string - standardized",
        "category": "programming_language | framework_library | database | cloud_platform | devops_infrastructure | tools_platforms | methodology_practice | domain_knowledge | soft_skill | other",
        "subcategory": "string | null - from taxonomy",
        "proficiency": {
          "stated": "expert | advanced | intermediate | beginner | learning | null",
          "inferred": "expert | advanced | intermediate | beginner | null",
          "inference_reason": "string | null"
        },
        "years_used": "number | null (if explicitly stated)",
        "last_used": "YYYY | null (if determinable from experience)",
        "context": "work | project | education | certification - where skill was mentioned"
      }
    ],
    "by_category": {
      "programming_language": ["names"],
      "framework_library": ["names"],
      "database": ["names"],
      "cloud_platform": ["names"],
      "devops_infrastructure": ["names"],
      "tools_platforms": ["names"],
      "methodology_practice": ["names"],
      "domain_knowledge": ["names"],
      "soft_skill": ["names"]
    },
    "primary_stack": ["top 5-7 most prominent technologies"],
    "unrecognized": ["skills not in taxonomy - may need review"]
  },
  
  "projects": [
    {
      "name": "string",
      "type": "personal | professional | academic | open_source | hackathon | freelance",
      "description": {
        "raw": "string - exact text, max 300 chars",
        "summary": "string - 1 sentence"
      },
      "technologies": ["list"],
      "role": "string | null - Solo, Lead, Contributor, etc.",
      "team_size": "number | null",
      "dates": {
        "start_year": "number | null",
        "end_year": "number | null"
      },
      "urls": {
        "repo": "string | null",
        "demo": "string | null",
        "documentation": "string | null"
      },
      "metrics": {
        "github_stars": "number | null",
        "users": "string | null",
        "downloads": "string | null",
        "other": "string | null"
      },
      "is_notable": "boolean"
    }
  ],
  
  "certifications": [
    {
      "name": {
        "raw": "string",
        "normalized": "string | null - from known database"
      },
      "issuer": "string | null",
      "code": "string | null (e.g., AWS SAA-C03)",
      "level": "foundational | associate | professional | specialty | expert | null",
      "date_obtained": {
        "raw": "string | null",
        "parsed": "YYYY-MM | YYYY | null"
      },
      "expiration_date": "YYYY-MM | null",
      "is_expired": "boolean | null",
      "credential_id": "string | null",
      "verification_url": "string | null",
      "skills_implied": ["list of skills this cert implies"]
    }
  ],
  
  "publications": [
    {
      "title": "string",
      "type": "journal_article | conference_paper | book | book_chapter | patent | blog_post | whitepaper | thesis | other",
      "publication_venue": "string | null - journal/conference name",
      "date": {
        "raw": "string | null",
        "year": "number | null"
      },
      "url": "string | null - DOI or direct link",
      "authors": {
        "raw": "string | null",
        "list": ["array of names"],
        "position": "first | last | middle | null - candidate's position"
      },
      "citations": "number | null (if mentioned)"
    }
  ],
  
  "awards": [
    {
      "title": "string",
      "issuer": "string | null",
      "date": {
        "raw": "string | null",
        "year": "number | null"
      },
      "description": "string | null",
      "is_notable": "boolean - true if from major organization"
    }
  ],
  
  "languages": [
    {
      "language": "string",
      "proficiency": {
        "raw": "string | null",
        "normalized": "native | bilingual | fluent | advanced | upper_intermediate | intermediate | basic | beginner | null",
        "cefr": "A1 | A2 | B1 | B2 | C1 | C2 | null"
      },
      "certifications": ["TOEFL", "IELTS", etc. if mentioned],
      "test_scores": {"test": "score"} | null
    }
  ],
  
  "coding_profiles": {
    "github": {
      "url": "string | null",
      "username": "string | null"
    },
    "leetcode": {"url": "string | null", "username": "string | null"},
    "hackerrank": {"url": "string | null", "username": "string | null"},
    "codeforces": {"url": "string | null", "username": "string | null"},
    "codechef": {"url": "string | null", "username": "string | null"},
    "kaggle": {"url": "string | null", "username": "string | null"},
    "stackoverflow": {"url": "string | null", "user_id": "string | null"},
    "toptal": {"url": "string | null"},
    "upwork": {"url": "string | null"},
    "other": [{"platform": "string", "url": "string"}]
  },
  
  "volunteer_experience": [
    {
      "organization": "string",
      "role": "string",
      "dates": {
        "start": "string | null",
        "end": "string | null"
      },
      "description": "string | null"
    }
  ],
  
  "interests": ["hobbies and interests if listed"],
  
  "references": {
    "available_upon_request": "boolean",
    "listed": [
      {
        "name": "string | null",
        "title": "string | null",
        "company": "string | null",
        "relationship": "string | null",
        "contact": "string | null - email or phone"
      }
    ]
  },
  
  "additional_sections": [
    {
      "header": "string - section name",
      "content": "string - raw content"
    }
  ],
  
  "search_index": {
    "full_text": "string - concatenated searchable text",
    "keywords": ["extracted keywords for search"],
    "job_titles_normalized": ["all normalized job titles"],
    "companies_normalized": ["all normalized company names"],
    "skills_normalized": ["all normalized skills"],
    "locations": ["all locations mentioned"]
  }
}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FINAL INSTRUCTIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. OUTPUT ONLY VALID JSON - No markdown, no explanations, no code blocks
2. USE null FOR MISSING DATA - Never fabricate or assume
3. PRESERVE ORIGINAL TEXT - Fix only clear OCR errors
4. DO NOT CALCULATE years_of_experience.stated - Only use if explicitly written
5. GENERATE HIGH-QUALITY SUMMARY - Follow templates, avoid banned phrases
6. CATEGORIZE ALL SKILLS - Use taxonomy, flag unknown
7. NORMALIZE COMPANY/SCHOOL NAMES - Use known databases
8. EXTRACT ALL METRICS - Numbers are gold for matching
9. FLAG QUALITY ISSUES - Help downstream systems
10. MAINTAIN INTERNATIONAL SUPPORT - Handle all locales and languages

NOW PARSE THE FOLLOWING RESUME:
"""


# ============================================================================
# Core Functions
# ============================================================================

def pdf_to_images(pdf_bytes: bytes, dpi: int = 150) -> List[bytes]:
    """
    Convert PDF to list of PNG images using PyMuPDF (no poppler dependency).
    
    Args:
        pdf_bytes: Raw PDF file bytes
        dpi: Resolution for conversion (default 150 for good quality without huge size)
    
    Returns:
        List of PNG image bytes, one per page
    """
    images = []
    pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
    
    # Scale factor for DPI (default PDF is 72 DPI)
    zoom = dpi / 72.0
    matrix = fitz.Matrix(zoom, zoom)
    
    for page_num in range(len(pdf_document)):
        page = pdf_document[page_num]
        pix = page.get_pixmap(matrix=matrix)
        img_bytes = pix.tobytes("png")
        images.append(img_bytes)
    
    pdf_document.close()
    return images


def _safe_get(obj, *keys, default=None):
    """Safely traverse nested dict/object."""
    for key in keys:
        if isinstance(obj, dict):
            obj = obj.get(key)
        else:
            return default
        if obj is None:
            return default
    return obj if obj is not None else default


def normalize_gemini_output(data: dict) -> dict:
    """
    Transform complex Gemini output to match simple Pydantic schemas.
    Handles the schema mismatch between elaborate prompt and existing models.
    """
    result = {}
    
    # Normalize personal_info
    pi = data.get("personal_info", {})
    result["personal_info"] = {
        "name": _safe_get(pi, "full_name") or _safe_get(pi, "name"),
        "email": _safe_get(pi, "email", "primary") or (pi.get("email") if isinstance(pi.get("email"), str) else None),
        "phone": _safe_get(pi, "phone", "primary", "raw") or _safe_get(pi, "phone", "raw") or (pi.get("phone") if isinstance(pi.get("phone"), str) else None),
        "linkedin_url": _safe_get(pi, "links", "linkedin", "url") or _safe_get(pi, "linkedin_url"),
        "github_url": _safe_get(pi, "links", "github", "url") or _safe_get(pi, "github_url"),
        "portfolio_url": _safe_get(pi, "links", "portfolio") or _safe_get(pi, "portfolio_url"),
        "location": _safe_get(pi, "location", "raw") or (pi.get("location") if isinstance(pi.get("location"), str) else None),
    }
    
    # Normalize professional_summary
    ps = data.get("professional_summary", "")
    if isinstance(ps, dict):
        result["professional_summary"] = _safe_get(ps, "generated") or _safe_get(ps, "original") or ""
    else:
        result["professional_summary"] = ps
    
    # Normalize years_of_experience - ONLY use if explicitly stated in resume
    # Never use calculated values to prevent wrong experience being shown
    yoe = data.get("years_of_experience") or data.get("career_metrics", {}).get("years_of_experience", {})
    if isinstance(yoe, dict):
        # Only use 'stated' experience, never 'calculated'
        result["years_of_experience"] = _safe_get(yoe, "stated")
    elif isinstance(yoe, (int, float)) and yoe > 0:
        # If it's a direct number, only use if it seems explicitly stated (whole numbers or .5)
        # Calculated values are often odd decimals like 0.33
        if yoe == int(yoe) or (yoe * 2) == int(yoe * 2):  # whole or .5
            result["years_of_experience"] = yoe
        else:
            result["years_of_experience"] = None  # Likely calculated, ignore
    else:
        result["years_of_experience"] = None
    
    # Get current role/company
    cm = data.get("career_metrics", {})
    result["current_role"] = cm.get("current_role") or data.get("current_role")
    result["current_company"] = cm.get("current_company") or data.get("current_company")
    
    # Normalize education
    education_list = []
    for edu in data.get("education", []):
        normalized_edu = {
            "school": _safe_get(edu, "institution", "name") or edu.get("school", "Unknown"),
            "degree": _safe_get(edu, "degree", "raw") or _safe_get(edu, "degree", "normalized") or (edu.get("degree") if isinstance(edu.get("degree"), str) else None),
            "field_of_study": _safe_get(edu, "field_of_study", "raw") or (edu.get("field_of_study") if isinstance(edu.get("field_of_study"), str) else None),
            "start_year": _safe_get(edu, "dates", "start_year") or edu.get("start_year"),
            "end_year": _safe_get(edu, "dates", "end_year") or edu.get("end_year"),
            "gpa": _safe_get(edu, "gpa", "raw") or (edu.get("gpa") if isinstance(edu.get("gpa"), str) else None),
        }
        education_list.append(normalized_edu)
    result["education"] = education_list
    
    # Normalize work_experience
    work_list = []
    for exp in data.get("work_experience", []):
        normalized_exp = {
            "company": _safe_get(exp, "company", "name") or (exp.get("company") if isinstance(exp.get("company"), str) else "Unknown"),
            "role": _safe_get(exp, "role", "title") or (exp.get("role") if isinstance(exp.get("role"), str) else "Unknown"),
            "city": _safe_get(exp, "location", "city") or exp.get("city"),
            "country": _safe_get(exp, "location", "country") or exp.get("country"),
            "start_date": _safe_get(exp, "dates", "start", "parsed") or exp.get("start_date"),
            "end_date": _safe_get(exp, "dates", "end", "parsed") or exp.get("end_date"),
            "is_current": _safe_get(exp, "dates", "is_current") or exp.get("is_current", False),
            "description": _safe_get(exp, "description", "raw") or (exp.get("description") if isinstance(exp.get("description"), str) else None),
        }
        work_list.append(normalized_exp)
    result["work_experience"] = work_list
    
    # Normalize projects
    project_list = []
    for proj in data.get("projects", []):
        normalized_proj = {
            "name": proj.get("name", "Unknown"),
            "description": _safe_get(proj, "description", "raw") or _safe_get(proj, "description", "summary") or (proj.get("description") if isinstance(proj.get("description"), str) else None),
            "technologies": proj.get("technologies", []),
            "start_year": _safe_get(proj, "dates", "start_year") or proj.get("start_year"),
            "end_year": _safe_get(proj, "dates", "end_year") or proj.get("end_year"),
            "url": _safe_get(proj, "urls", "repo") or _safe_get(proj, "urls", "demo") or proj.get("url"),
        }
        project_list.append(normalized_proj)
    result["projects"] = project_list
    
    # Normalize skills
    skills_data = data.get("skills", [])
    skill_list = []
    
    if isinstance(skills_data, dict):
        # Complex format with "all" key
        raw_skills = skills_data.get("all", [])
    else:
        raw_skills = skills_data
    
    for skill in raw_skills:
        if isinstance(skill, dict):
            prof = skill.get("proficiency", {})
            normalized_skill = {
                "name": skill.get("normalized_name") or skill.get("name", ""),
                "category": skill.get("category"),
                "proficiency": (prof.get("stated") or prof.get("inferred") if isinstance(prof, dict) else prof),
            }
            skill_list.append(normalized_skill)
        elif isinstance(skill, str):
            skill_list.append({"name": skill, "category": None, "proficiency": None})
    result["skills"] = skill_list
    
    # Normalize certifications
    cert_list = []
    for cert in data.get("certifications", []):
        normalized_cert = {
            "title": _safe_get(cert, "name", "raw") or _safe_get(cert, "name", "normalized") or cert.get("title", "Unknown"),
            "issuer": cert.get("issuer"),
            "year": _safe_get(cert, "date_obtained", "parsed")[:4] if _safe_get(cert, "date_obtained", "parsed") else cert.get("year"),
            "url": cert.get("verification_url") or cert.get("url"),
        }
        if isinstance(normalized_cert["year"], str):
            try:
                normalized_cert["year"] = int(normalized_cert["year"][:4])
            except:
                normalized_cert["year"] = None
        cert_list.append(normalized_cert)
    result["certifications"] = cert_list
    
    # Normalize publications
    pub_list = []
    for pub in data.get("publications", []):
        normalized_pub = {
            "title": pub.get("title", "Unknown"),
            "publisher": pub.get("publication_venue") or pub.get("publisher"),
            "year": _safe_get(pub, "date", "year") or pub.get("year"),
            "url": pub.get("url"),
        }
        pub_list.append(normalized_pub)
    result["publications"] = pub_list
    
    # Normalize awards
    award_list = []
    for award in data.get("awards", []):
        normalized_award = {
            "title": award.get("title", "Unknown"),
            "issuer": award.get("issuer"),
            "year": _safe_get(award, "date", "year") or award.get("year"),
        }
        award_list.append(normalized_award)
    result["awards"] = award_list
    
    # Normalize languages
    lang_list = []
    for lang in data.get("languages", []):
        normalized_lang = {
            "language": lang.get("language", "Unknown"),
            "proficiency": _safe_get(lang, "proficiency", "normalized") or (lang.get("proficiency") if isinstance(lang.get("proficiency"), str) else None),
        }
        lang_list.append(normalized_lang)
    result["languages"] = lang_list
    
    # Normalize coding_profiles
    cp = data.get("coding_profiles", {})
    result["coding_profiles"] = {
        "leetcode": _safe_get(cp, "leetcode", "username") or (cp.get("leetcode") if isinstance(cp.get("leetcode"), str) else None),
        "github": _safe_get(cp, "github", "username") or (cp.get("github") if isinstance(cp.get("github"), str) else None),
        "codechef": _safe_get(cp, "codechef", "username") or (cp.get("codechef") if isinstance(cp.get("codechef"), str) else None),
        "codeforces": _safe_get(cp, "codeforces", "username") or (cp.get("codeforces") if isinstance(cp.get("codeforces"), str) else None),
    }
    
    return result


async def parse_resume_with_gemini(pdf_bytes: bytes) -> ParsedResume:
    """
    Parse resume PDF using Gemini vision model.

    Args:
        pdf_bytes: Raw PDF file bytes

    Returns:
        ParsedResume object with all extracted data

    Note: Uses asyncio.to_thread for CPU-bound PDF conversion and
          async Gemini API for true concurrent processing.
    """
    import asyncio

    # Convert PDF to images in thread pool (CPU-bound, don't block event loop)
    images = await asyncio.to_thread(pdf_to_images, pdf_bytes)

    if not images:
        raise ValueError("Could not extract any pages from PDF")

    # Prepare content parts for Gemini
    client = get_genai_client()
    if not client:
        raise ValueError("Gemini API not configured. Please set GEMINI_API_KEY.")

    from google import genai
    contents = [RESUME_PARSER_PROMPT]

    for img_bytes in images:
        # Add image as Part
        contents.append(
            genai.types.Part.from_bytes(
                data=img_bytes,
                mime_type="image/png"
            )
        )

    # Generate response using ASYNC API (non-blocking, allows concurrent parsing)
    response = await client.aio.models.generate_content(
        model=settings.gemini_model,
        contents=contents,
        config=genai.types.GenerateContentConfig(
            temperature=0.1,
            max_output_tokens=32768,
        )
    )
    
    # Extract and parse JSON
    response_text = response.text.strip()
    
    # Clean up response if it has markdown code blocks
    if response_text.startswith("```json"):
        response_text = response_text[7:]
    if response_text.startswith("```"):
        response_text = response_text[3:]
    if response_text.endswith("```"):
        response_text = response_text[:-3]
    response_text = response_text.strip()
    
    try:
        parsed_data = json.loads(response_text)
        # Normalize the complex Gemini output to match our simple Pydantic schemas
        normalized_data = normalize_gemini_output(parsed_data)
        return ParsedResume(**normalized_data)
    except json.JSONDecodeError as e:
        print(f"Failed to parse JSON response: {e}")
        print(f"Raw response: {response_text[:500]}...")
        
        # Try to repair truncated JSON
        repaired = repair_truncated_json(response_text)
        if repaired:
            print("Successfully repaired truncated JSON")
            normalized_data = normalize_gemini_output(repaired)
            return ParsedResume(**normalized_data)
        
        # Return empty parsed resume on failure
        return ParsedResume()
    except Exception as e:
        print(f"Failed to parse resume: {e}")
        # Return empty parsed resume on failure
        return ParsedResume()


def normalize_skill_name(skill_name: str) -> str:
    """Normalize skill name for consistent storage and matching."""
    # Common aliases mapping
    aliases = {
        "js": "javascript",
        "ts": "typescript",
        "py": "python",
        "cpp": "c++",
        "c#": "csharp",
        "node": "nodejs",
        "node.js": "nodejs",
        "react.js": "react",
        "vue.js": "vue",
        "angular.js": "angular",
        "mongo": "mongodb",
        "postgres": "postgresql",
        "k8s": "kubernetes",
        "tf": "terraform",
        "aws lambda": "aws",
        "gcp": "google cloud",
        "ml": "machine learning",
        "ai": "artificial intelligence",
        "dl": "deep learning",
    }
    
    normalized = skill_name.lower().strip()
    return aliases.get(normalized, normalized)


def deduplicate_skills(skills: List[SkillEntry]) -> List[SkillEntry]:
    """Remove duplicate skills, keeping the one with highest proficiency."""
    proficiency_order = {"expert": 3, "intermediate": 2, "beginner": 1, None: 0}
    
    skill_map = {}
    for skill in skills:
        normalized = normalize_skill_name(skill.name)
        current = skill_map.get(normalized)
        
        if current is None:
            skill_map[normalized] = skill
        else:
            # Keep the one with higher proficiency
            if proficiency_order.get(skill.proficiency, 0) > proficiency_order.get(current.proficiency, 0):
                skill_map[normalized] = skill
    
    return list(skill_map.values())


# ============================================================================
# Robust JSON Handling & Background Processing
# ============================================================================

def repair_truncated_json(raw_response: str) -> dict | None:
    """
    Attempt to repair truncated JSON responses from Gemini.
    This handles cases where the API returns cut-off output.
    
    Strategy:
    1. Try parsing as-is
    2. Find the last complete object/array
    3. Close open braces/brackets
    """
    import re
    text = raw_response.strip()
    
    # Remove markdown code blocks if present
    if text.startswith("```json"):
        text = text[7:]
    if text.startswith("```"):
        text = text[3:]
    if text.endswith("```"):
        text = text[:-3]
    text = text.strip()
    
    # Try parsing as-is first
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        pass
    
    # Strategy 1: Find last complete structure and truncate there
    # Look for positions where we have a complete key-value pair
    last_valid_pos = -1
    
    # Try progressively truncating from the end
    for cutoff_marker in ['},', '},\n', '"],', '],', '"}', '"]']:
        pos = text.rfind(cutoff_marker)
        if pos > last_valid_pos:
            last_valid_pos = pos + len(cutoff_marker) - 1
    
    if last_valid_pos > 0:
        text = text[:last_valid_pos]
    
    # Strategy 2: Close any remaining open structures
    # Remove trailing incomplete content (partial strings, etc.)
    # Find the last closing brace/bracket
    while text and text[-1] not in ']}':
        # Remove characters until we hit a structural character
        text = text[:-1]
    
    if not text:
        return None
    
    # Count open vs closed braces/brackets
    open_braces = text.count('{') - text.count('}')
    open_brackets = text.count('[') - text.count(']')
    
    # Close in reverse order (inner to outer)
    # Generally arrays are inside objects in JSON responses
    text += ']' * max(0, open_brackets)
    text += '}' * max(0, open_braces)
    
    try:
        return json.loads(text)
    except json.JSONDecodeError as e:
        print(f"JSON repair failed: {e}")
        return None


async def parse_resume_safe(pdf_bytes: bytes, max_retries: int = 3) -> tuple[ParsedResume | None, str | None]:
    """
    Parse resume with robust error handling, retries, and API key rotation.

    Features:
    - Retries on transient failures with exponential backoff
    - Automatically rotates to backup API key on quota errors (429)
    - Ensures parsing succeeds if ANY configured API key has quota

    Args:
        pdf_bytes: PDF file content
        max_retries: Number of retry attempts per API key

    Returns:
        Tuple of (ParsedResume or None, error_message or None)
    """
    import asyncio

    last_error = None
    total_attempts = 0
    max_total_attempts = max_retries * max(_gemini_pool.available_clients_count, 1)

    while total_attempts < max_total_attempts:
        attempt_in_key = total_attempts % max_retries
        total_attempts += 1

        try:
            result = await parse_resume_with_gemini(pdf_bytes)
            # Check if we got meaningful data
            if result.professional_summary or result.work_experience or result.education:
                return (result, None)
            # Empty result - might be parsing issue, retry
            if total_attempts < max_total_attempts:
                await asyncio.sleep(2 ** attempt_in_key)  # Exponential backoff
                continue
            return (result, None)  # Return empty result on last attempt

        except json.JSONDecodeError as e:
            last_error = f"JSON parse error: {str(e)}"
            print(f"Attempt {total_attempts}/{max_total_attempts}: {last_error}")
            if total_attempts < max_total_attempts:
                await asyncio.sleep(2 ** attempt_in_key)
                continue

        except Exception as e:
            error_str = str(e)
            last_error = f"Parsing error: {error_str}"
            print(f"Attempt {total_attempts}/{max_total_attempts}: {last_error}")

            # Check if it's a quota error - try rotating to another API key
            if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str or "quota" in error_str.lower():
                print(f"ğŸ”´ Quota exceeded on current API key")
                if rotate_gemini_client():
                    print(f"ğŸŸ¢ Switched to backup API key, retrying...")
                    # Don't count this as a failed attempt - we have a fresh key
                    total_attempts -= 1
                    await asyncio.sleep(1)  # Brief pause before retry
                    continue
                else:
                    # All keys exhausted
                    last_error = "All Gemini API keys have hit quota limits. Please try again later or add more API keys."
                    break

            if total_attempts < max_total_attempts:
                await asyncio.sleep(2 ** attempt_in_key)
                continue

    return (None, last_error)

